{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pytesseract\n",
    "import torch\n",
    "import multiprocess\n",
    "import numpy as np\n",
    "from datasets import DatasetDict\n",
    "from PIL import Image\n",
    "\n",
    "# zeige keine Warnungen an\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.ocr_pipeline import OCRPreprocessor, OCRPostProcessor\n",
    "from src.utils import rotate_image, pil_to_cv, from_cv_to_pil\n",
    "\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz initialisieren\n",
    "dataset = DatasetDict.load_from_disk(\"../data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "class OCRPipeline:\n",
    "    def __init__(self, image: Union[np.ndarray, Image.Image]):\n",
    "        \"\"\"OCR-Pipeline zu Vorbereitung des Dokumentes, \n",
    "        Extraktion des Textes und Aufbereitung des extrahierten Textes.\n",
    "\n",
    "        Args:\n",
    "            Args:\n",
    "            image (Union[np.ndarray, Image.Image]): Das Eingangsbild als NumPy-Array oder PIL.Image.Image.\n",
    "        \"\"\"\n",
    "        self.raw_image = image\n",
    "        self.preprocessed_image = None\n",
    "        self.ocr_output = \"\"\n",
    "\n",
    "    def preprocess(self) -> None:\n",
    "        \"\"\"Initialisiert und wendet den OCRPreprocessor an, speichert das verarbeitete Bild.\"\"\"\n",
    "        preprocessor = OCRPreprocessor(self.raw_image)\n",
    "        preprocessor.cropping(buffer_size=10)\n",
    "        preprocessor.resize(factor=3)\n",
    "        preprocessor.contrast_stretching()\n",
    "        preprocessor.power_law_transform(gamma=2)\n",
    "        preprocessor.to_gray()\n",
    "        #preprocessor.correct_skew()\n",
    "        preprocessor.sharpen(kernel_type=\"laplace_standard\")\n",
    "        preprocessor.opening(kernel=(1,1), iterations=2)\n",
    "        preprocessor.power_law_transform(gamma=2)\n",
    "        self.preprocessed_image = preprocessor.get_image()\n",
    "\n",
    "    def extract_text(self) -> None:\n",
    "        \"\"\"Wendet PyTesseract auf das vorverarbeitete Bild an und speichert den Text.\"\"\"\n",
    "        self.ocr_output = pytesseract.image_to_string(self.preprocessed_image)\n",
    "\n",
    "    def postprocess(self) -> None:\n",
    "        \"\"\"Initialisiert und wendet den OCRPostProcessor auf den extrahierten Text an.\"\"\"\n",
    "        if self.ocr_output.strip():  # Prüft, ob `ocr_output` nicht leer ist\n",
    "            postprocessor = OCRPostProcessor(self.ocr_output)\n",
    "            # Anwenden verschiedener Methoden\n",
    "            postprocessor.identify_language()\n",
    "            postprocessor.remove_special_characters()\n",
    "            postprocessor.remove_stopwords()\n",
    "            #postprocessor.stem()\n",
    "            #postprocessor.lemmatize()\n",
    "            postprocessor.lowercase()\n",
    "            postprocessor.spellcheck(checker_type=\"symspell\")\n",
    "            \n",
    "            # Aufbereiteten OCR-Output extrahieren\n",
    "            self.ocr_output = postprocessor.get_text()\n",
    "        else:\n",
    "            self.ocr_output = \"no text found in image with ocr!\"\n",
    "\n",
    "    def get_output(self):\n",
    "        \"\"\"Gibt den aufbereiteten OCR-Output zurück.\"\"\"\n",
    "        return self.ocr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ocr_to_dataset(dataset: DatasetDict) -> DatasetDict:\n",
    "    \"\"\"\n",
    "    Diese Methode wendet die OCR (Optical Character Recognition) auf alle Bilder in jedem Split (train, validation, test) eines Huggingface-Datensatzes an und fügt ein neues Feature hinzu, das den erkannten Text enthält.\n",
    "    \"\"\"\n",
    "    def add_ocr_text(example: dict) -> dict:\n",
    "        image = example['image']\n",
    "            \n",
    "        ocr_pipeline = OCRPipeline(image)\n",
    "            \n",
    "        ocr_pipeline.preprocess()\n",
    "\n",
    "        ocr_pipeline.extract_text()\n",
    "            \n",
    "        ocr_pipeline.postprocess()\n",
    "\n",
    "        example['tesseract_text'] = ocr_pipeline.get_output()\n",
    "            \n",
    "        return example\n",
    "    \n",
    "     # Anwenden der Funktion auf jeden Split im Datensatz\n",
    "    for split in dataset.keys():\n",
    "        dataset[split] = dataset[split].map(add_ocr_text, keep_in_memory=False)\n",
    "            \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "processed_dataset = apply_ocr_to_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "processed_dataset = apply_ocr_to_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prüfen ob kein string im Feature \"Text\" leer ist in allen drei Datensätzen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset.save_to_disk(\"../data/processed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
