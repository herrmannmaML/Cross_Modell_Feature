{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import warnings\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "from datasets import DatasetDict\n",
    "from PIL import Image\n",
    "\n",
    "# zeige keine Warnungen an\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.ocr_pipeline import OCRPreprocessor, OCRPostProcessor\n",
    "from src.utils import rotate_image, pil_to_cv, from_cv_to_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datensatz initialisieren\n",
    "dataset = DatasetDict.load_from_disk(\"../data/interim_rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_preprocessor_wrapper(example: dict) -> dict:\n",
    "    \"\"\"Initialisiert und wendet den OCRPreprocessor an, speichert das verarbeitete Bild.\"\"\"\n",
    "    preprocessor = OCRPreprocessor(example['image'])\n",
    "    preprocessor.cropping(buffer_size=10)\n",
    "    preprocessor.contrast_stretching()\n",
    "    preprocessor.to_gray()\n",
    "    preprocessor.correct_skew()\n",
    "    preprocessor.sharpen(kernel_type=\"laplace_standard\")\n",
    "    preprocessor.opening(kernel=(1,1), iterations=2)\n",
    "    preprocessor.power_law_transform(gamma=2)\n",
    "    example['image-ocr'] = preprocessor.get_image()\n",
    "        \n",
    "    return example\n",
    "\n",
    "def ocr_postprocessor_wrapper(example: dict, text_column: str) -> dict:\n",
    "    \"\"\"Initialisiert und wendet den OCRPostProcessor auf den extrahierten Text an.\"\"\"\n",
    "    if example[text_column].strip():  # Prüft, ob `ocr_output` nicht leer ist\n",
    "        postprocessor = OCRPostProcessor(example[text_column])\n",
    "        # Anwenden verschiedener Methoden\n",
    "        postprocessor.identify_language()\n",
    "        postprocessor.remove_special_characters()\n",
    "        postprocessor.lowercase()\n",
    "        postprocessor.remove_stopwords()\n",
    "        postprocessor.remove_extra_spaces()\n",
    "        # Aufbereiteten OCR-Output extrahieren\n",
    "        example[text_column] = postprocessor.get_text()\n",
    "    else:\n",
    "        example[text_column] = \"no text found in document image with ocr!\"\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import concurrent.futures\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from typing import Callable, Dict, List\n",
    "import multiprocessing\n",
    "multiprocessing.set_start_method('spawn', force=True)\n",
    "\n",
    "class OCRPipeline:\n",
    "    def __init__(self, dataset: Dict) -> None:\n",
    "        # Initialisierung der OCRPipeline mit einem Datensatz.\n",
    "        self.dataset = dataset\n",
    "        # Ein Wörterbuch zur Speicherung der geladenen OCR-Engines.\n",
    "        self.engines = {}\n",
    "        \n",
    "    def _load_engine(self, engine_name: str) -> None:\n",
    "        \"\"\"Lädt die angegebene OCR-Engine, falls noch nicht geladen.\"\"\"\n",
    "        # Lädt OCR-Engines dynamisch, um Ressourcen effizient zu nutzen.\n",
    "        if engine_name == 'easyocr' and 'easyocr' not in self.engines:\n",
    "            self.engines['easyocr'] = \"easyocr\"\n",
    "        elif engine_name == 'doctr' and 'doctr' not in self.engines:\n",
    "            self.engines['doctr'] = \"doctr\"\n",
    "    \n",
    "    def _run_tesseract(self, num_proc: int) -> None:\n",
    "        \"\"\"Verwendet Tesseract OCR, um Text aus Bildern in einem Datensatz zu extrahieren.\"\"\"\n",
    "        texts = []\n",
    "        with ProcessPoolExecutor(max_workers=num_proc) as executor:\n",
    "            futures = [executor.submit(pytesseract.image_to_string, image) for image in self.dataset[\"image_ocr\"]]\n",
    "            # Fortschrittsbalken zur Überwachung des Prozesses.\n",
    "            for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures), desc=\"OCR Processing\"):\n",
    "                # Speichert das Ergebnis jeder fertigen Aufgabe.\n",
    "                texts.append(future.result())\n",
    "        # Fügt die extrahierten Texte als neue Spalte zum Datensatz hinzu.\n",
    "        self.dataset = self.dataset.add_column(\"text\", texts)\n",
    "     \n",
    "    \n",
    "    def preprocess(self, preprocessor_fn: Callable, num_proc: int = 1) -> None:\n",
    "        \"\"\"Wendet eine Preprocessing-Funktion auf den Datensatz an.\"\"\"\n",
    "        self.dataset = self.dataset.map(preprocessor_fn, num_proc=num_proc)\n",
    "        logging.info(\"OCR-Preprocessor erfolgreich auf Datensatz angewendet.\")\n",
    "    \n",
    "    \n",
    "    def extract_text(self, ocr_engines: List[str], batched: bool = True, batch_size: int = 4, num_proc: int = 1) -> None:\n",
    "        \"\"\"Extrahiert Text unter Verwendung der angegebenen OCR-Engines.\"\"\"\n",
    "        for engine in ocr_engines:\n",
    "\n",
    "            if engine == 'tesseract':\n",
    "                self._run_tesseract(num_proc=num_proc)\n",
    "                logging.info(\"Tesseract-OCR-Engine erfolgreich auf Datensatz angewendet\")\n",
    "            else:\n",
    "                logging.error(f\"Angegebene OCR-Engine '{engine}' nicht implementiert. Nur 'tesseract', 'easyocr', 'doctr' nutzbar.\")\n",
    "\n",
    "    def postprocess(self, postprocessor_fn: Callable, text_column: str, num_proc: int = 1) -> None:\n",
    "        \"\"\"Wendet eine Postprocessing-Funktion auf extrahierten Text im Datensatz an.\"\"\"\n",
    "        self.dataset = self.dataset.map(\n",
    "            postprocessor_fn,\n",
    "            fn_kwargs={'text_column': text_column},\n",
    "            num_proc=num_proc\n",
    "        )\n",
    "        logging.info(\"OCR-Postprocessor erfolgreich auf Datensatz angewendet.\")\n",
    "\n",
    "    def get_data(self) -> Dict:\n",
    "        \"\"\"Gibt den verarbeiteten Datensatz zurück.\"\"\"\n",
    "        return self.dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=2):  29%|██▉       | 153/523 [01:15<03:02,  2.03 examples/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the subprocesses has abruptly died during map operation.To debug the error, disable multiprocessing.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m ocr_pipeline \u001b[38;5;241m=\u001b[39m OCRPipeline(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 3\u001b[0m \u001b[43mocr_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mocr_preprocessor_wrapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mOCRPipeline.preprocess\u001b[0;34m(self, preprocessor_fn, num_proc)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, preprocessor_fn: Callable, num_proc: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wendet eine Preprocessing-Funktion auf den Datensatz an.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessor_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOCR-Preprocessor erfolgreich auf Datensatz angewendet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    556\u001b[0m }\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/arrow_dataset.py:3197\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3191\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3192\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3193\u001b[0m     unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3194\u001b[0m     total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3195\u001b[0m     desc\u001b[38;5;241m=\u001b[39m(desc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (num_proc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3196\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miflatmap_unordered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs_per_job\u001b[49m\n\u001b[1;32m   3199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3201\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/utils/py_utils.py:656\u001b[0m, in \u001b[0;36miflatmap_unordered\u001b[0;34m(pool, func, kwargs_iterable)\u001b[0m\n\u001b[1;32m    654\u001b[0m             pool_changed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    655\u001b[0m             \u001b[38;5;66;03m# One of the subprocesses has died. We should not wait forever.\u001b[39;00m\n\u001b[0;32m--> 656\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    657\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the subprocesses has abruptly died during map operation.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    658\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo debug the error, disable multiprocessing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    659\u001b[0m             )\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[1;32m    662\u001b[0m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: One of the subprocesses has abruptly died during map operation.To debug the error, disable multiprocessing."
     ]
    }
   ],
   "source": [
    "ocr_pipeline = OCRPipeline(dataset[\"test\"])\n",
    "\n",
    "ocr_pipeline.preprocess(preprocessor_fn=ocr_preprocessor_wrapper, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_pipeline.extract_text(batched=True, batch_size=4, num_proc=1, ocr_engines = [\"tesseract\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocr_pipeline.postprocess(postprocessor_fn=ocr_postprocessor_wrapper, text_column=\"text\", num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ocr_pipeline.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion, die prüft, ob der Text leer ist\n",
    "def is_empty_string(example):\n",
    "    return example[\"text\"] == \"\"\n",
    "\n",
    "# Zählen der leeren Strings in jedem Split\n",
    "empty_counts = {}\n",
    "for split in dataset.keys():\n",
    "    empty_count = sum(1 for example in dataset[split] if is_empty_string(example))\n",
    "    empty_counts[split] = empty_count\n",
    "\n",
    "# Ausgabe der Ergebnisse\n",
    "for split, count in empty_counts.items():\n",
    "    print(f\"Anzahl der leeren Strings im '{split}'-Split: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset.save_to_disk(\"../data/processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
